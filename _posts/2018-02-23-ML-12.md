---
layout: post
title:  " NN의 꽃 RNN 이야기 "
categories: MachineLearning
tags: MachineLearning
author: goodGid
---
* content
{:toc}


<iframe width="560" height="315" src="https://www.youtube.com/embed/-SHPG_KMUkQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

[Source](https://github.com/nlintz/TensorFlow-Tutorials)

---

## Sequence Data

{% capture images %}
/assets/img/machine_learning/ML_12_1_1.png
{% endcapture %}
{% include gallery images=images caption=" " cols=1 %} 


기존에는 시리즈 데이터가 아닌 

독립적인 데이터였다.


<br>


{% capture images %}
/assets/img/machine_learning/ML_12_1_2.png
{% endcapture %}
{% include gallery images=images caption=" " cols=1 %} 

현재 State가 다음 State에 영향을 끼친다.
 
시리즈인 데이터에 적합한 모델이다.

`Notice`를 주의깊게 보자.


---

## Recurrent Neural Network

{% capture images %}
/assets/img/machine_learning/ML_12_1_3.png
{% endcapture %}
{% include gallery images=images caption=" " cols=1 %} 

x라는 입력값과 이전의 값으로 

어떤 함수 fx()에 넣어서

새로운 상태값(=Ht)을 구한다.

---


## Example Character-level language Model

{% capture images %}
/assets/img/machine_learning/ML_12_1_4.png
{% endcapture %}
{% include gallery images=images caption=" " cols=1 %} 

hidden layer을 보면

그 전에 값이 현재 값에 영향을 미친다.

즉 이전에 값들을 기억한다고 볼 수 있다.


그리고 Y값을 뽑아낼 때

{% capture images %}
/assets/img/machine_learning/ML_12_1_5.png
{% endcapture %}
{% include gallery images=images caption=" " cols=1 %} 

---

## Multi-Layer RNN

{% capture images %}
/assets/img/machine_learning/ML_12_1_6.png
{% endcapture %}
{% include gallery images=images caption=" " cols=1 %} 


1개의 Layer가 아닌

여러개의 Layer도 가능하다.